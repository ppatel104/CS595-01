{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"ride_data1.csv\")\n",
    "data2 = pd.read_csv(\"ride_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data1,data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_review</th>\n",
       "      <th>ride_rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had just completed running the New York Mara...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My appointment time for auto repairs required ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whether I am using Uber for a ride service or ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why is it so hard for you to understand that i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was in South Beach, FL. I was staying at a m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ride_review  ride_rating  sentiment\n",
       "0  I had just completed running the New York Mara...          1.0          0\n",
       "1  My appointment time for auto repairs required ...          1.0          0\n",
       "2  Whether I am using Uber for a ride service or ...          1.0          0\n",
       "3  Why is it so hard for you to understand that i...          1.0          0\n",
       "4  I was in South Beach, FL. I was staying at a m...          1.0          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "with open(\"stopwords_stanford\") as f:\n",
    "    stanford_sw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stanford_sw = [x.strip() for x in stanford_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sw = list(set(stopwords + stanford_sw + list(stop_words.ENGLISH_STOP_WORDS)))\n",
    "sw = [x.lower() for x in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(text):\n",
    "    sb = SnowballStemmer(\"english\")\n",
    "    for i in range(0,len(text['ride_review'])):\n",
    "        tokens = word_tokenize(text['ride_review'].iloc[i])\n",
    "        tokens = [x.lower() for x in tokens if x.lower() not in sw]\n",
    "        tokens = list(filter(lambda x:x.isalpha(),tokens))\n",
    "        stem_tokens = [sb.stem(x) for x in tokens]\n",
    "        c = Counter()\n",
    "        c.update(stem_tokens)\n",
    "        d = dict(c)\n",
    "        seen = set()\n",
    "        result = []\n",
    "        for item in tokens:\n",
    "            if sb.stem(item) not in seen:\n",
    "                seen.add(sb.stem(item))\n",
    "                result.append(item)\n",
    "        review = ' '.join(x for x in result)\n",
    "        text['ride_review'].iloc[i] = review\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purvank/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "pro_data = data_preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed new requested let tell started right driver agreed pick drop locations called spoke know actually blocked pickup away race road got notification rider joining spoken shortly passenger went wrong moments continuing destination phone asked going claimed need confused far time clearly played dumb saying understand works middle strange wanting argue lucrative jerk peacefully exited stood private residence shivering cold degree rainy weather dark mile safe seek rest warmth safety sooner scrawling fare piece paper standing outside meet inkling conscientiousness nerve charge partial excited using taxis coming lyft connected minutes long warm dressed clothes weary expecting stranded pace wait main traffic heavy rode closures able realistic eternal happiness arrived delivered nicely day finding way file complaint sent couple hours replied wet blanket apology inconvenience offered credit make worse taken wrote corrected harm previous good reputation earned pay preserve relationships better certainly dangerous situation mention discipline told experiences past years bad apple ruined forever'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_data['ride_review'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_data.to_csv(\"cv_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f = open(\"example.txt\", \"w\")\n",
    "#f.write(\"\\n\".join(map(lambda x: str(x), l)))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1,3),min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = tf_idf.fit_transform(pro_data[\"ride_review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_data1 = pd.DataFrame(d1,columns=tf_idf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "stem_tokens = [sb.stem(x) for x in tf_idf.get_feature_names()]\n",
    "c = Counter()\n",
    "c.update(stem_tokens)\n",
    "d = dict(c)\n",
    "deleted = []\n",
    "print (type(tf_idf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(tf_idf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seen = set()\n",
    "result = []\n",
    "for item in a:\n",
    "    if sb.stem(item) not in seen:\n",
    "        seen.add(sb.stem(item))\n",
    "        result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_data2 = n_data1[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 1563)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purvank/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "n_data2['sentiment'] = pro_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 1564)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_data1['sentiment'] = pro_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data2.to_csv(\"data2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
